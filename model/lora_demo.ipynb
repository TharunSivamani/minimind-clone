{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cad33f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from model_lora import load_lora, apply_lora, save_lora, LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e791d85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 16)  # square → LoRA will be added\n",
    "        self.fc2 = nn.Linear(16, 8)   # NOT square → no LoRA here\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01614c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleModel().to(\"cuda\")\n",
    "apply_lora(model, rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f79f57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (fc1): Linear(\n",
       "    in_features=16, out_features=16, bias=True\n",
       "    (lora): LoRA(\n",
       "      (A): Linear(in_features=16, out_features=4, bias=False)\n",
       "      (B): Linear(in_features=4, out_features=16, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a359af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LoRA attached?  True\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoRA attached? \", hasattr(model.fc1, \"lora\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b380316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA attached to fc2?  False\n"
     ]
    }
   ],
   "source": [
    "print(\"LoRA attached to fc2? \", hasattr(model.fc2, \"lora\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5a1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random input\n",
    "x = torch.randn(1, 16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7055fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Forward pass (with LoRA) ===\n",
      "Output before modifying LoRA:\n",
      " tensor([[-0.0787,  0.1393, -0.1625, -0.4562,  0.4278, -0.0659, -0.1931, -0.2288]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Forward pass (with LoRA) ===\")\n",
    "out1 = model(x)\n",
    "print(\"Output before modifying LoRA:\\n\", out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac3a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modify LoRA weights ===\n"
     ]
    }
   ],
   "source": [
    "# Modify LoRA weights so changes will be visible after load\n",
    "print(\"\\n=== Modify LoRA weights ===\")\n",
    "with torch.no_grad():\n",
    "    model.fc1.lora.A.weight.fill_(0.123)\n",
    "    model.fc1.lora.B.weight.fill_(0.456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfff6de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after modifying LoRA:\n",
      " tensor([[-0.2364,  0.4143, -0.2315, -0.3902,  0.5948,  0.0542, -0.1554,  0.0761]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out2 = model(x)\n",
    "print(\"Output after modifying LoRA:\\n\", out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e0662f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_lora(model, \"lora_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c900609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Create new model and load LoRA ===\n"
     ]
    }
   ],
   "source": [
    "# Create a NEW model and apply LoRA again\n",
    "print(\"\\n=== Create new model and load LoRA ===\")\n",
    "model2 = SimpleModel().to(\"cuda\")\n",
    "apply_lora(model2, rank=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e15935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model output before loading LoRA:\n",
      " tensor([[ 0.1949,  0.1155, -0.3426, -0.3066, -0.2650, -0.4405,  0.1356,  0.1195]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Before loading: different output\n",
    "out3 = model2(x)\n",
    "print(\"New model output before loading LoRA:\\n\", out3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cca8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LoRA weights\n",
    "load_lora(model2, \"lora_weights.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2203f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New model output after loading LoRA:\n",
      " tensor([[ 0.1410,  0.4229, -0.5414, -0.3217, -0.4193, -0.3787,  0.2722,  0.2433]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# After loading: must match modified output\n",
    "out4 = model2(x)\n",
    "print(\"\\nNew model output after loading LoRA:\\n\", out4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
